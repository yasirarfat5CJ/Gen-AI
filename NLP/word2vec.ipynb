{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340bfc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/yasirarfat18/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yasirarfat18/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/yasirarfat18/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yasirarfat18/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /home/yasirarfat18/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b7865e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['learning' 'love' 'machine' 'nlp']\n",
      "Bow matrix:\n",
      " [[0 1 0 1]\n",
      " [1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "#bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "input=[\n",
    "    \"I love NLP\",\n",
    "    \"I love Machine Learning\"\n",
    "]\n",
    "cv=CountVectorizer()\n",
    "X=cv.fit_transform(input)\n",
    "\n",
    "print(\"Vocabulary:\",cv.get_feature_names_out())\n",
    "print(\"Bow matrix:\\n\",X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbd7a34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: ['learning' 'love' 'machine' 'nlp']\n",
      "TF-IDF Matrix:\n",
      " [[0.         0.57973867 0.         0.81480247]\n",
      " [0.6316672  0.44943642 0.6316672  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf=TfidfVectorizer()\n",
    "\n",
    "docs=[\n",
    "    \"I love NLP\",\n",
    "    \"I love Machine learning\"\n",
    "]\n",
    "X=tfidf.fit_transform(docs)\n",
    "print(\"Vocabulary:\",tfidf.get_feature_names_out())\n",
    "print(\"TF-IDF Matrix:\\n\", X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cc5992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00515624 -0.00666834 -0.00777684  0.00831073 -0.00198234 -0.00685496\n",
      " -0.00415439  0.00514413 -0.00286914 -0.00374966  0.00162143 -0.00277629\n",
      " -0.00158436  0.00107449 -0.00297794  0.00851928  0.00391094 -0.00995886\n",
      "  0.0062596  -0.00675425  0.00076943  0.00440423 -0.00510337 -0.00211067\n",
      "  0.00809548 -0.00424379 -0.00763626  0.00925791 -0.0021555  -0.00471943\n",
      "  0.0085708   0.00428334  0.00432484  0.00928451 -0.00845308  0.00525532\n",
      "  0.00203935  0.00418828  0.0016979   0.00446413  0.00448629  0.00610452\n",
      " -0.0032021  -0.00457573 -0.00042652  0.00253373 -0.00326317  0.00605772\n",
      "  0.00415413  0.00776459  0.00256927  0.00811668 -0.00138721  0.00807793\n",
      "  0.00371702 -0.00804732 -0.00393361 -0.00247188  0.00489304 -0.00087216\n",
      " -0.00283091  0.00783371  0.0093229  -0.00161493 -0.00515925 -0.00470176\n",
      " -0.00484605 -0.00960283  0.00137202 -0.00422492  0.00252671  0.00561448\n",
      " -0.00406591 -0.00959658  0.0015467  -0.00670012  0.00249517 -0.00378063\n",
      "  0.00707842  0.00064022  0.00356094 -0.00273913 -0.00171055  0.00765279\n",
      "  0.00140768 -0.00585045 -0.0078345   0.00123269  0.00645463  0.00555635\n",
      " -0.00897705  0.00859216  0.00404698  0.00746961  0.00974633 -0.00728958\n",
      " -0.00903996  0.005836    0.00939121  0.00350693]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentences = [\n",
    "    [\"I\", \"love\", \"natural\", \"language\", \"processing\"],\n",
    "    [\"Word2Vec\", \"creates\", \"word\", \"embeddings\"],\n",
    "    [\"machine\", \"learning\", \"is\", \"fun\"]\n",
    "]\n",
    "\n",
    "model=Word2Vec(sentences,vector_size=100,window=5,min_count=1,sg=1)\n",
    "vector = model.wv[\"language\"]\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428abd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
