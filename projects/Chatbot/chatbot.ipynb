{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6011c653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30623885",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08669ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/run/media/yasirarfat18/D/GenAI/projects/py311-projects/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatGroq(profile={'max_input_tokens': 131072, 'max_output_tokens': 8192, 'image_inputs': False, 'audio_inputs': False, 'video_inputs': False, 'image_outputs': False, 'audio_outputs': False, 'video_outputs': False, 'reasoning_output': False, 'tool_calling': True}, client=<groq.resources.chat.completions.Completions object at 0x7fbc0e3fa510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fbc0e154890>, model_name='llama-3.1-8b-instant', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23f7b305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Yasir Arfat. It's great to hear that you're in your 3rd year of B.Tech CSE and exploring the exciting field of General AI (also known as AGI or Artificial General Intelligence) and Full Stack Development.\\n\\nGeneral AI is an area that's gaining significant attention in the tech industry, and it has the potential to revolutionize various aspects of our lives. As a CSE student, you're well-positioned to explore this field and learn about the latest advancements in AI.\\n\\nFull Stack Development, on the other hand, is a valuable skill that allows you to work on both the front-end and back-end of web applications. It's a great skill to have, especially in today's digital age.\\n\\nWhat specific areas of General AI are you interested in exploring? Are you working on any projects related to AI or machine learning? And which programming languages and technologies are you using for Full Stack Development?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 192, 'prompt_tokens': 61, 'total_tokens': 253, 'completion_time': 0.431810041, 'completion_tokens_details': None, 'prompt_time': 0.004817517, 'prompt_tokens_details': None, 'queue_time': 0.049967173, 'total_time': 0.436627558}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-9da4-72d0-a649-892370558aea-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 61, 'output_tokens': 192, 'total_tokens': 253})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage,AIMessage\n",
    "\n",
    "model.invoke([HumanMessage(content=\"hi my name is yasir arfat iam in 3rd year of BTech cse exploring gen-ai fullstack dev\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875fe3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_messege_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f1179aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4566fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "res=with_messege_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name is yasir arfat iam in 3rd year of BTech cse exploring gen-ai fullstack dev\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52153d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Yasir Arfat. It's great to hear that you're in your 3rd year of BTech CSE and exploring Generative AI and Full Stack Development.\\n\\nGenerative AI is an exciting field that has been gaining traction in recent years, with applications in areas such as natural language processing, computer vision, and music generation. Full Stack Development, on the other hand, requires a broad range of skills, from front-end development to back-end development, and database management.\\n\\nWhat specific aspects of Generative AI are you interested in? Are you working on any projects that involve Generative AI or Full Stack Development? I'd be happy to help if you have any questions or need any guidance.\\n\\nAlso, have you explored any popular libraries or frameworks for Generative AI, such as TensorFlow, PyTorch, or Keras? And for Full Stack Development, are you familiar with the MERN (MongoDB, Express, React, Node.js) or MEAN (MongoDB, Express, Angular, Node.js) stack?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4609a68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Yasir Arfat.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 288, 'total_tokens': 297, 'completion_time': 0.003807595, 'completion_tokens_details': None, 'prompt_time': 0.016995577, 'prompt_tokens_details': None, 'queue_time': 0.050627413, 'total_time': 0.020803172}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-a3d5-7d00-809a-07d006a39666-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 288, 'output_tokens': 9, 'total_tokens': 297})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_messege_history.invoke(\n",
    "    [HumanMessage(content=\"wht is my name\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e92c82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a large language model, I don't have the ability to know or remember personal information about individual users. Each time you interact with me, it's a new conversation and I don't retain any information from previous conversations.\\n\\nIf you'd like to share your name with me, I'd be happy to chat with you and remember it for the duration of our conversation.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 40, 'total_tokens': 126, 'completion_time': 0.109301462, 'completion_tokens_details': None, 'prompt_time': 0.002658853, 'prompt_tokens_details': None, 'queue_time': 0.050987387, 'total_time': 0.111960315}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-a499-7870-a82f-3f52924df47a-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 40, 'output_tokens': 86, 'total_tokens': 126})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "with_messege_history.invoke(\n",
    "    [HumanMessage(content=\"wht is my name\")],\n",
    "    config=config1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54419280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant.Answer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9bd1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Yasir Arfat. I'm here to assist you with any questions or information you may need. How's your day going so far?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 60, 'total_tokens': 94, 'completion_time': 0.040732672, 'completion_tokens_details': None, 'prompt_time': 0.002886194, 'prompt_tokens_details': None, 'queue_time': 0.056258346, 'total_time': 0.043618866}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-a688-7950-851c-7ca2277e5abc-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 60, 'output_tokens': 34, 'total_tokens': 94})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is  yasir arfat\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9737ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_messege_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a22ca1d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Nice to meet you, Yasir Arfat. It's great that you're starting a conversation with me. How can I assist you today? Do you have any questions, need help with a project, or just want to chat about a topic you're interested in? I'm all ears (or rather, all text)!\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 66, 'prompt_tokens': 159, 'total_tokens': 225, 'completion_time': 0.095215319, 'completion_tokens_details': None, 'prompt_time': 0.010787449, 'prompt_tokens_details': None, 'queue_time': 0.056326991, 'total_time': 0.106002768}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-a7ba-7e33-b69d-114c61b86eb0-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 159, 'output_tokens': 66, 'total_tokens': 225})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config={\"configurable\":{'session_id':\"chat2\"}}\n",
    "res=with_messege_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name is yasir arfat\")],\n",
    "    config=config)\n",
    "\n",
    "res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae5fda32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते यासिर अरफत, मैं आपकी सहायता करने के लिए तैयार हूँ। आप किस बारे में पूछना चाहते हैं?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 63, 'total_tokens': 113, 'completion_time': 0.067294813, 'completion_tokens_details': None, 'prompt_time': 0.003436598, 'prompt_tokens_details': None, 'queue_time': 0.055873902, 'total_time': 0.070731411}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019ba60e-a8e1-7d30-a73a-370211540289-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 63, 'output_tokens': 50, 'total_tokens': 113})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adding more complexity\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"you are a helpful assistant.Answer all the question to the best of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model\n",
    "\n",
    "res=chain.invoke({\"messages\":[HumanMessage(content=\"Hi  my  name is yasir arfat\")],\"language\":\"hindi\"})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03fe4372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'నమస్కారం, నేను సహాయకుడిని. నీవు యాసిర్ అన్నావు. నేను నీకు సహాయం చేస్తాను. ఏమి అవసరం?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=with_messege_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "config={\"configurable\":{'session_id':\"chat3\"}}\n",
    "\n",
    "res=with_messege_history.invoke({\"messages\":[HumanMessage(content=\"hi my name is yasir\")],\"language\":\"telugu\"},config=config)\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6929bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='you are a good assistant' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=5,          # now treated as MESSAGE COUNT\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,    \n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "\n",
    "msgs = [\n",
    "    SystemMessage(content=\"you are a good assistant\"),\n",
    "    HumanMessage(\n",
    "        content=\"hi how are u.my name is yasir arfat what are you doing now. I am heading to 4th year, what suggestions will you give for my upcoming interviews?\"\n",
    "    ),\n",
    "    AIMessage(content=\"nice\")\n",
    "]\n",
    "\n",
    "trimmed_msgs = trimmer.invoke(msgs)\n",
    "print(trimmed_msgs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97896025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm glad to hear that I can be a helpful assistant. I'm here to provide information and answer any questions you may have to the best of my abilities. What would you like to know or discuss today?\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        response=(\n",
    "            RunnablePassthrough.assign(\n",
    "                messages=itemgetter(\"messages\") | trimmer\n",
    "            )\n",
    "            | prompt\n",
    "            | model\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "result = chain.invoke({\n",
    "    \"messages\": msgs + [HumanMessage(content=\"what is my name?\")],\n",
    "    \"language\": \"English\"\n",
    "})\n",
    "\n",
    "print(result[\"response\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "203e5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "with_messege_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": \"chat5\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54b9e1e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('output')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='what is my name', additional_kwargs={}, response_metadata={})],\n",
       " 'language': 'telugu',\n",
       " 'response': 'నేను సహాయకుడిగా ఉన్నాను. మీ అడిగిన ఏదైనా ప్రశ్నకు సమాధానం ఇవ్వడానికి నేను ఇష్టపడతాను. మీ అడిగిన ప్రశ్నను అడిగింది. \\n\\nమీ ప్రశ్న ఏమిటి?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res=with_messege_history.invoke({\"messages\":[HumanMessage(content=\"what is my name\")],\"language\":\"telugu\"},config=config)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19d8c05e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'nlp_notes.pdf', 'topic': 'Transformers', 'level': 'beginner', 'page': 1}, page_content='Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.'),\n",
       " Document(metadata={'source': 'attention_blog', 'topic': 'Self-Attention', 'level': 'intermediate', 'page': 3}, page_content='Self-attention allows a model to weigh the importance of different words in a sentence relative to each other. This helps capture long-range dependencies better than RNNs or LSTMs.'),\n",
       " Document(metadata={'source': 'langchain_docs', 'topic': 'LangChain', 'level': 'beginner', 'page': 5}, page_content='LangChain is a framework for building applications powered by large language models. It provides tools for prompt management, chains, agents, memory, and integrations with vector databases.'),\n",
       " Document(metadata={'source': 'vector_db_guide', 'topic': 'Embeddings', 'level': 'intermediate', 'page': 2}, page_content='Embeddings are numerical representations of text that capture semantic meaning. They enable similarity search, clustering, and retrieval-augmented generation (RAG).'),\n",
       " Document(metadata={'source': 'rag_whitepaper', 'topic': 'RAG', 'level': 'advanced', 'page': 10}, page_content='Retrieval-Augmented Generation (RAG) combines information retrieval with text generation. Relevant documents are retrieved from a knowledge base and passed to an LLM to generate accurate responses.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.\",\n",
    "        metadata={\n",
    "            \"source\": \"nlp_notes.pdf\",\n",
    "            \"topic\": \"Transformers\",\n",
    "            \"level\": \"beginner\",\n",
    "            \"page\": 1\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    Document(\n",
    "        page_content=\"Self-attention allows a model to weigh the importance of different words in a sentence relative to each other. This helps capture long-range dependencies better than RNNs or LSTMs.\",\n",
    "        metadata={\n",
    "            \"source\": \"attention_blog\",\n",
    "            \"topic\": \"Self-Attention\",\n",
    "            \"level\": \"intermediate\",\n",
    "            \"page\": 3\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    Document(\n",
    "        page_content=\"LangChain is a framework for building applications powered by large language models. It provides tools for prompt management, chains, agents, memory, and integrations with vector databases.\",\n",
    "        metadata={\n",
    "            \"source\": \"langchain_docs\",\n",
    "            \"topic\": \"LangChain\",\n",
    "            \"level\": \"beginner\",\n",
    "            \"page\": 5\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    Document(\n",
    "        page_content=\"Embeddings are numerical representations of text that capture semantic meaning. They enable similarity search, clustering, and retrieval-augmented generation (RAG).\",\n",
    "        metadata={\n",
    "            \"source\": \"vector_db_guide\",\n",
    "            \"topic\": \"Embeddings\",\n",
    "            \"level\": \"intermediate\",\n",
    "            \"page\": 2\n",
    "        }\n",
    "    ),\n",
    "\n",
    "    Document(\n",
    "        page_content=\"Retrieval-Augmented Generation (RAG) combines information retrieval with text generation. Relevant documents are retrieved from a knowledge base and passed to an LLM to generate accurate responses.\",\n",
    "        metadata={\n",
    "            \"source\": \"rag_whitepaper\",\n",
    "            \"topic\": \"RAG\",\n",
    "            \"level\": \"advanced\",\n",
    "            \"page\": 10\n",
    "        }\n",
    "    ),\n",
    "]\n",
    "documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "262e6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2c232c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bbfd243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(id='e097cc28-5682-4c58-81bf-1732379a3922', metadata={'level': 'beginner', 'topic': 'Transformers', 'page': 1, 'source': 'nlp_notes.pdf'}, page_content='Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.'),\n",
       "  1.269553542137146),\n",
       " (Document(id='e9025bdc-5925-4ec7-aad3-e0a7224ee4ca', metadata={'page': 1, 'topic': 'Transformers', 'level': 'beginner', 'source': 'nlp_notes.pdf'}, page_content='Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.'),\n",
       "  1.269553542137146),\n",
       " (Document(id='6dc842d4-0b5c-4ab4-8f2a-898333a3eef6', metadata={'source': 'vector_db_guide', 'level': 'intermediate', 'topic': 'Embeddings', 'page': 2}, page_content='Embeddings are numerical representations of text that capture semantic meaning. They enable similarity search, clustering, and retrieval-augmented generation (RAG).'),\n",
       "  1.2907427549362183),\n",
       " (Document(id='5e3204ca-77b0-4c33-a398-9ba1e97585e9', metadata={'topic': 'Embeddings', 'page': 2, 'source': 'vector_db_guide', 'level': 'intermediate'}, page_content='Embeddings are numerical representations of text that capture semantic meaning. They enable similarity search, clustering, and retrieval-augmented generation (RAG).'),\n",
       "  1.2907427549362183)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vectorstores: it helpus to covert text to embedding and store in db\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "llm=ChatGroq(model=\"llama-3.1-8b-instant\",groq_api_key=groq_api_key)\n",
    "llm\n",
    "\n",
    "db=Chroma.from_documents(documents,embedding=embeddings)\n",
    "\n",
    "db.similarity_search(\"nlp\")\n",
    "\n",
    "## Async query\n",
    "await db.asimilarity_search_with_score(\"nlp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e598b483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='e9025bdc-5925-4ec7-aad3-e0a7224ee4ca', metadata={'page': 1, 'topic': 'Transformers', 'source': 'nlp_notes.pdf', 'level': 'beginner'}, page_content='Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.')],\n",
       " [Document(id='2d552027-b366-49b5-94e9-31d6e8dff9a1', metadata={'level': 'intermediate', 'source': 'attention_blog', 'topic': 'Self-Attention', 'page': 3}, page_content='Self-attention allows a model to weigh the importance of different words in a sentence relative to each other. This helps capture long-range dependencies better than RNNs or LSTMs.')]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##retreivers\n",
    "from typing  import List\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "retreiver=RunnableLambda(db.similarity_search).bind(k=1)\n",
    "retreiver.batch([\"nlp\",\"self-attention\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ed0e166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Document(id='e9025bdc-5925-4ec7-aad3-e0a7224ee4ca', metadata={'source': 'nlp_notes.pdf', 'topic': 'Transformers', 'page': 1, 'level': 'beginner'}, page_content='Transformers are deep learning models based on self-attention mechanisms. They process entire sequences in parallel and are widely used in NLP tasks such as translation, summarization, and question answering.')],\n",
       " [Document(id='2d552027-b366-49b5-94e9-31d6e8dff9a1', metadata={'topic': 'Self-Attention', 'page': 3, 'source': 'attention_blog', 'level': 'intermediate'}, page_content='Self-attention allows a model to weigh the importance of different words in a sentence relative to each other. This helps capture long-range dependencies better than RNNs or LSTMs.')]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retreiver=db.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":1}\n",
    ")\n",
    "retreiver.batch([\"nlp\",\"self-attention\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba6a78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (projects)",
   "language": "python",
   "name": "py311-projects"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
